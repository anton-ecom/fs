/**
 * Google Cloud Storage FileSystem Demo
 * 
 * This demo showcases the GCS FileSystem capabilities using real cloud storage.
 * 
 * Usage:
 *   npm run build
 *   node examples/gcs-demo.js
 */

import { createGCSFileSystem, type GCSFileSystemOptions } from '../dist/promises/gcs';
import * as fs from 'fs';
import * as path from 'path';

async function runGCSDemo() {
  console.log('üöÄ SYNET FS - Google Cloud Storage Demo\n');

  try {
    // Load credentials
    const testConfigPath = path.join(__dirname, '../private/google-test-access.json');
    const testConfig = JSON.parse(fs.readFileSync(testConfigPath, 'utf8'));
    const serviceAccountPath = path.join(__dirname, '../private', testConfig.key);

    console.log(`üìÅ Project: ${testConfig.projectId}`);
    console.log(`ü™£ Bucket: ${testConfig.bucketName}`);
    console.log(`üîë Service Account: ${path.basename(testConfig.key)}\n`);

    // Initialize GCS FileSystem
    const gcsOptions: GCSFileSystemOptions = {
      projectId: testConfig.projectId,
      bucket: testConfig.bucketName,
      keyFilename: serviceAccountPath,
      prefix: 'demo' // Use demo prefix
    };

    const gcsFS = createGCSFileSystem(gcsOptions);
    console.log('‚úÖ GCS FileSystem initialized\n');

    // Demo 1: Simple file operations
    console.log('üìÑ Demo 1: Basic File Operations');
    console.log('‚îÄ'.repeat(40));
    
    const simpleFile = `demo-${Date.now()}.txt`;
    const simpleContent = `Hello from SYNET FS GCS Demo!

This file was created on: ${new Date().toISOString()}
Random ID: ${Math.random()}
    
SYNET Unit Architecture provides:
- Consciousness-based software design
- Teaching/Learning capabilities between units
- Immutable evolution patterns
- Capability composition over inheritance`;

    await gcsFS.writeFile(simpleFile, simpleContent);
    console.log(`‚úÖ Uploaded: ${simpleFile}`);

    const exists = await gcsFS.exists(simpleFile);
    console.log(`‚úÖ File exists: ${exists}`);

    const readContent = await gcsFS.readFile(simpleFile);
    console.log(`‚úÖ Read back: ${readContent.length} bytes`);
    console.log(`üìÑ Preview: ${readContent.substring(0, 100)}...\n`);

    // Demo 2: JSON configuration files
    console.log('‚öôÔ∏è  Demo 2: JSON Configuration');
    console.log('‚îÄ'.repeat(40));
    
    const configFile = `config/app-config-${Date.now()}.json`;
    const config = {
      app: {
        name: 'SYNET Application',
        version: '1.0.0',
        environment: 'production'
      },
      storage: {
        backend: 'Google Cloud Storage',
        bucket: testConfig.bucketName,
        encryption: true
      },
      features: {
        unitArchitecture: true,
        teachingContracts: true,
        immutableEvolution: true,
        capabilityComposition: true
      },
      metadata: {
        createdAt: new Date().toISOString(),
        createdBy: 'SYNET FS GCS Demo',
        purpose: 'Demonstrate JSON configuration storage'
      }
    };

    await gcsFS.writeFile(configFile, JSON.stringify(config, null, 2));
    console.log(`‚úÖ Uploaded config: ${configFile}`);

    const configContent = await gcsFS.readFile(configFile);
    const parsedConfig = JSON.parse(configContent);
    console.log(`‚úÖ Config app name: ${parsedConfig.app.name}`);
    console.log(`‚úÖ Config features: ${Object.keys(parsedConfig.features).length} enabled\n`);

    // Demo 3: Directory operations
    console.log('üìÇ Demo 3: Directory Operations');
    console.log('‚îÄ'.repeat(40));
    
    const docFiles = [
      'docs/README.md',
      'docs/API.md',
      'docs/examples/quickstart.md'
    ];

    const docContents = [
      '# SYNET FS GCS\n\nGoogle Cloud Storage adapter for SYNET Unit Architecture.',
      '# API Documentation\n\n## Methods\n\n- `writeFile()`\n- `readFile()`\n- `exists()`',
      '# Quick Start\n\n```typescript\nconst gcs = createGCSFileSystem(options);\n```'
    ];

    // Upload documentation files
    for (let i = 0; i < docFiles.length; i++) {
      await gcsFS.writeFile(docFiles[i], docContents[i]);
      console.log(`‚úÖ Uploaded: ${docFiles[i]}`);
    }

    // List directory contents
    const docsListing = await gcsFS.readDir('docs');
    console.log(`üìÇ docs/ contains: ${docsListing.join(', ')}`);

    const examplesListing = await gcsFS.readDir('docs/examples');
    console.log(`üìÇ docs/examples/ contains: ${examplesListing.join(', ')}\n`);

    // Demo 4: File statistics
    console.log('üìä Demo 4: File Statistics');
    console.log('‚îÄ'.repeat(40));
    
    const stats = await gcsFS.stat(simpleFile);
    console.log(`üìÑ File: ${simpleFile}`);
    console.log(`üìè Size: ${stats.size} bytes`);
    console.log(`üìÖ Modified: ${stats.mtime.toISOString()}`);
    console.log(`üîí Mode: ${stats.mode.toString(8)}`);
    console.log(`üìÅ Is file: ${stats.isFile()}`);
    console.log(`üìÇ Is directory: ${stats.isDirectory()}\n`);

    // Demo 5: Concurrent operations
    console.log('‚ö° Demo 5: Concurrent Operations');
    console.log('‚îÄ'.repeat(40));
    
    const concurrentFiles = Array.from({ length: 5 }, (_, i) => ({
      name: `concurrent/batch-${i}-${Date.now()}.txt`,
      content: `Concurrent file ${i}\nTimestamp: ${new Date().toISOString()}\nBatch upload test`
    }));

    console.time('Concurrent upload');
    await Promise.all(
      concurrentFiles.map(file => gcsFS.writeFile(file.name, file.content))
    );
    console.timeEnd('Concurrent upload');

    console.time('Concurrent read');
    const readResults = await Promise.all(
      concurrentFiles.map(file => gcsFS.readFile(file.name))
    );
    console.timeEnd('Concurrent read');

    console.log(`‚úÖ Successfully processed ${concurrentFiles.length} files concurrently\n`);

    // Demo 6: Cache performance
    console.log('üóÑÔ∏è  Demo 6: Cache Performance');
    console.log('‚îÄ'.repeat(40));
    
    console.time('First read (from GCS)');
    await gcsFS.readFile(simpleFile);
    console.timeEnd('First read (from GCS)');

    console.time('Second read (from cache)');
    await gcsFS.readFile(simpleFile);
    console.timeEnd('Second read (from cache)');

    console.time('Third read (from cache)');
    await gcsFS.readFile(simpleFile);
    console.timeEnd('Third read (from cache)');

    // Clear cache and read again
    gcsFS.clearCache();
    console.time('After cache clear');
    await gcsFS.readFile(simpleFile);
    console.timeEnd('After cache clear');
    console.log('‚úÖ Cache performance test completed\n');

    // Summary
    console.log('üìã Demo Summary');
    console.log('‚ïê'.repeat(40));
    console.log('‚úÖ Basic file upload/download');
    console.log('‚úÖ JSON configuration handling');
    console.log('‚úÖ Directory operations');
    console.log('‚úÖ File statistics and metadata');
    console.log('‚úÖ Concurrent operations');
    console.log('‚úÖ Cache performance optimization');
    console.log('‚úÖ Error handling and graceful failures');

    // Cleanup
    console.log('\nüßπ Cleaning up demo files...');
    const allDemoFiles = [
      simpleFile,
      configFile,
      ...docFiles,
      ...concurrentFiles.map(f => f.name)
    ];

    for (const file of allDemoFiles) {
      try {
        await gcsFS.deleteFile(file);
      } catch (error) {
        console.log(`‚ö†Ô∏è  Could not delete ${file}: ${error}`);
      }
    }

    // Clean up directories
    try {
      await gcsFS.deleteDir('concurrent');
      await gcsFS.deleteDir('docs');
      await gcsFS.deleteDir('config');
    } catch (error) {
      console.log(`‚ö†Ô∏è  Directory cleanup: ${error}`);
    }

    console.log('‚úÖ Demo cleanup completed');
    console.log('\nüéâ GCS Demo finished successfully!');

  } catch (error) {
    console.error('\n‚ùå Demo failed:', error);
    process.exit(1);
  }
}

// Run demo if called directly
if (require.main === module) {
  runGCSDemo().catch(console.error);
}

export { runGCSDemo };
