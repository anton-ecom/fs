/**
 * Azure Blob Storage FileSystem Demo
 * 
 * This demo showcases the Azure Blob Storage FileSystem capabilities using real cloud storage.
 * 
 * Usage:
 *   npm run build
 *   node examples/azure-demo.js
 */

import { createAzureBlobStorageFileSystem, type AzureBlobStorageOptions } from '../src/promises/azure';
import * as fs from 'fs';
import * as path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

async function runAzureDemo() {
  console.log('ğŸš€ SYNET FS - Azure Blob Storage Demo\n');

  try {
    // Load credentials
    const testConfigPath = path.join(__dirname, '../private/azyre-test-access.json');
    const testConfig = JSON.parse(fs.readFileSync(testConfigPath, 'utf8'));

    console.log(`ğŸ“ Container: ${testConfig.containerName}`);
    console.log(`ğŸ”— Account: hsfstest`);
    console.log(`ğŸ”‘ Using connection string authentication\n`);

    // Initialize Azure Blob Storage FileSystem
    const azureOptions: AzureBlobStorageOptions = {
      connectionString: testConfig.connectionString,
      containerName: testConfig.containerName,
      prefix: 'demo' // Use demo prefix
    };

    const azureFS = createAzureBlobStorageFileSystem(azureOptions);
    console.log('âœ… Azure Blob Storage FileSystem initialized\n');

    // Demo 1: Simple file operations
    console.log('ğŸ“„ Demo 1: Basic File Operations');
    const textFile = `demo-text-${Date.now()}.txt`;
    const textContent = `Hello Azure Blob Storage from SYNET FS!\n\nThis is a demonstration of the Azure adapter.\nTimestamp: ${new Date().toISOString()}`;
    
    await azureFS.writeFile(textFile, textContent);
    console.log(`  âœ… Wrote: ${textFile}`);
    
    const readContent = await azureFS.readFile(textFile);
    console.log(`  âœ… Read: ${readContent.length} bytes`);
    console.log(`  ğŸ“– Preview: "${readContent.substring(0, 50)}..."\n`);

    // Demo 2: JSON file handling
    console.log('ğŸ“„ Demo 2: JSON File Operations');
    const jsonFile = `demo-data-${Date.now()}.json`;
    const jsonData = {
      project: 'SYNET FS',
      adapter: 'Azure Blob Storage',
      timestamp: Date.now(),
      features: ['async operations', 'cloud storage', 'caching', 'directory simulation'],
      metadata: {
        version: '1.0.0',
        author: 'SYNET',
        performance: {
          upload: 'fast',
          download: 'cached',
          concurrent: 'supported'
        }
      }
    };
    
    await azureFS.writeFile(jsonFile, JSON.stringify(jsonData, null, 2));
    console.log(`  âœ… Wrote JSON: ${jsonFile}`);
    
    const readJsonContent = await azureFS.readFile(jsonFile);
    const parsedData = JSON.parse(readJsonContent);
    console.log(`  âœ… Read and parsed JSON successfully`);
    console.log(`  ğŸ“Š Features: ${parsedData.features.join(', ')}\n`);

    // Demo 3: Directory operations
    console.log('ğŸ“‚ Demo 3: Directory Operations');
    const baseDir = `demo-directory-${Date.now()}`;
    
    // Create nested file structure
    await azureFS.writeFile(`${baseDir}/readme.md`, '# Demo Directory\n\nThis directory contains demo files.');
    await azureFS.writeFile(`${baseDir}/config.json`, '{"setting": "demo"}');
    await azureFS.writeFile(`${baseDir}/logs/app.log`, 'Demo log entry 1\nDemo log entry 2');
    await azureFS.writeFile(`${baseDir}/data/users.json`, '[{"id": 1, "name": "Demo User"}]');
    
    console.log(`  âœ… Created nested file structure in: ${baseDir}`);
    
    // List directory contents
    const contents = await azureFS.readDir(baseDir);
    console.log(`  ğŸ“‚ Directory contents: ${contents.join(', ')}`);
    
    // List subdirectory
    const logContents = await azureFS.readDir(`${baseDir}/logs`);
    console.log(`  ğŸ“ Logs directory: ${logContents.join(', ')}\n`);

    // Demo 4: File statistics
    console.log('ğŸ“Š Demo 4: File Statistics');
    const stats = await azureFS.stat(textFile);
    console.log(`  ğŸ“ File size: ${stats.size} bytes`);
    console.log(`  ğŸ•’ Modified: ${stats.mtime.toISOString()}`);
    console.log(`  ğŸ“„ Is file: ${stats.isFile()}`);
    console.log(`  ğŸ“ Is directory: ${stats.isDirectory()}\n`);

    // Demo 5: Concurrent operations
    console.log('âš¡ Demo 5: Concurrent Operations');
    const concurrentPromises: Promise<void>[] = [];
    const concurrentBase = Date.now();
    
    for (let i = 0; i < 5; i++) {
      const fileName = `concurrent-demo-${concurrentBase}-${i}.txt`;
      const content = `Concurrent file ${i}\nUploaded at: ${new Date().toISOString()}`;
      concurrentPromises.push(azureFS.writeFile(fileName, content));
    }
    
    const startTime = Date.now();
    await Promise.all(concurrentPromises);
    const duration = Date.now() - startTime;
    
    console.log(`  âœ… Uploaded 5 files concurrently in ${duration}ms\n`);

    // Demo 6: Cache performance
    console.log('ğŸ—„ï¸  Demo 6: Cache Performance');
    const cacheFile = `cache-demo-${Date.now()}.txt`;
    const cacheContent = 'This file will be cached for performance testing.';
    
    await azureFS.writeFile(cacheFile, cacheContent);
    
    // First read (will cache)
    const readStart1 = Date.now();
    await azureFS.readFile(cacheFile);
    const readTime1 = Date.now() - readStart1;
    
    // Second read (from cache)
    const readStart2 = Date.now();
    await azureFS.readFile(cacheFile);
    const readTime2 = Date.now() - readStart2;
    
    console.log(`  ğŸ“– First read: ${readTime1}ms (network + cache)`);
    console.log(`  ğŸ“– Second read: ${readTime2}ms (cache only)`);
    
    if (readTime2 < readTime1) {
      console.log(`  ğŸš€ Cache improved performance by ${((readTime1 - readTime2) / readTime1 * 100).toFixed(1)}%\n`);
    }

    // Demo 7: Container information
    console.log('â„¹ï¸  Demo 7: Container Information');
    const containerInfo = azureFS.getContainerInfo();
    console.log(`  ğŸ“ Container: ${containerInfo.containerName}`);
    console.log(`  ğŸ“‚ Prefix: ${containerInfo.prefix}`);
    console.log(`  ğŸ”‘ Auth method: ${containerInfo.hasConnectionString ? 'Connection String' : 'Account Key'}`);
    
    if (containerInfo.blobServiceEndpoint) {
      console.log(`  ğŸŒ Endpoint: ${containerInfo.blobServiceEndpoint}`);
    }
    console.log();

    // Cleanup
    console.log('ğŸ§¹ Demo Cleanup');
    const cleanupFiles = [
      textFile,
      jsonFile,
      cacheFile,
      ...Array.from({length: 5}, (_, i) => `concurrent-demo-${concurrentBase}-${i}.txt`)
    ];
    
    for (const file of cleanupFiles) {
      try {
        await azureFS.deleteFile(file);
        console.log(`  âœ… Deleted: ${file}`);
      } catch (error) {
        console.log(`  âš ï¸  Could not delete ${file}: ${(error as Error).message}`);
      }
    }
    
    // Delete demo directory
    try {
      await azureFS.deleteDir(baseDir);
      console.log(`  âœ… Deleted directory: ${baseDir}`);
    } catch (error) {
      console.log(`  âš ï¸  Could not delete directory ${baseDir}: ${(error as Error).message}`);
    }

    console.log('\nğŸ‰ Azure Blob Storage Demo completed successfully!');
    console.log('\nğŸ“š Summary of demonstrated features:');
    console.log('  âœ… File read/write operations');
    console.log('  âœ… JSON file handling');
    console.log('  âœ… Directory operations and listing');
    console.log('  âœ… File statistics and metadata');
    console.log('  âœ… Concurrent operations');
    console.log('  âœ… Performance caching');
    console.log('  âœ… Container information access');
    console.log('  âœ… Cleanup and deletion');

  } catch (error) {
    console.error('âŒ Demo failed:', error);
    process.exit(1);
  }
}

// Run the demo
runAzureDemo().catch(console.error);
